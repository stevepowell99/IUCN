# First data attempts for IUCN project

First, we grab the ISO country names from WB and regional codes (i.e. West and Central Africa) from UN and combine them, resulting in a vector of  codes for the countries we are interested in.

Then we grab some data using the API for the world bank WDIs (World Development Indicators,also available at google public data). 

Then we standardise them so that the mean is always zero and standard deviation 1, to make comparison between indicators easier.

The first chart shows time series for this first batch of indicators.


```{r,echo=FALSE,cache=TRUE,message=FALSE,warning=FALSE,fig.height=9,fig.width=11}
library(ggplot2)
library(WDI)
library(stringr)
library(RCurl)
library(XML)
clean=function(x)gsub("<[^>]*>", "",gsub("\n","",x))
xc=function(stri,sepp=" ") (strsplit(stri, sepp)[[1]]) 

html2txt <- function(str) {
      xpathApply(htmlParse(str, asText=TRUE),
                 "//body//text()", 
                 xmlValue)[[1]] 
}

usecache=T
if(usecache){
  mbz=readRDS(file = "objects/mbz")
  ppi=readRDS(file = "objects/ppi")
  monaco=readRDS(file = "objects/monaco")
  cepf=readRDS(file = "objects/cepf")

}

allcountries=read.csv("/home/steve/steve@promente.net/Methods/R-methods/mapAndCountryDataStuff/ISO-3166-Countries-with-Regional-Codes/all/all.csv", stringsAsFactors=F)

WAfCodes=allcountries[,2][allcountries[,7]=="11"]
CAfCodes=allcountries[,2][allcountries[,7]=="17"]
WAfNames=allcountries[,1][allcountries[,7]=="11"]
CAfNames=allcountries[,1][allcountries[,7]=="17"]

CWAfCodes=na.omit(c(WAfCodes,CAfCodes))
CWAfNames=na.omit(c(WAfNames,CAfNames))
CWAfNames=na.omit(c("Democratic Republic of Congo",CWAfNames))


if(!usecache){



inds=list()
inds$th=data.frame(t(WDIsearch("threatened")[1,]))
inds$bi=data.frame(t(WDIsearch("biodiversity")))
inds$ir=data.frame(t(WDIsearch("irrigated")[1,]))
inds$fo=data.frame(WDIsearch("forest")[c(3,8),])
inds$pr=data.frame(t(WDIsearch("Terrestrial")[2,]))
inds$ru=data.frame(WDIsearch("rural")[c(1,29,36),])
inds$hd=data.frame(t(WDIsearch("HDI")[3,]))
inds$fw=data.frame(t(WDIsearch("freshwater")[6,]))
inds$ag=data.frame(t(WDIsearch("agricultural")[4,]))
inds$ra=data.frame(t(WDIsearch("precipitation")))
inds$nr=data.frame((WDIsearch("natural resources")))

th=do.call(rbind,(inds))
# CWAfCodes=CWAfCodes[1:13]
all=lapply(1:nrow(th),function(x){
df=data.frame(WDI(country=CWAfCodes, indicator=th[x,1], start=2005, end=2014))
if(ncol(df)>0){
colnames(df)[3]="value"
df$indicator=th[x,2]
df$scaled=scale(df$value)
df
}
#   ddply(df,.variables = c("iso2c","country","indicator","year"),.fun = max)
})


alldf=(do.call(rbind,(all)))
alldf=na.omit(alldf)
saveRDS(alldf,"alldf")
} else alldf=readRDS(file = "alldf")

label_wrap <- function(variable, value) {
  lapply(strwrap(as.character(value), width=12, simplify=FALSE), 
         paste, collapse="\n")
}  


```

```{r}
# ggplot(alldf[1:100,],aes(year,scaled))+facet_grid(country~indicator,scales = "free",labeller = label_wrap)+geom_line()
# +geom_rect(aes(x=1,y=0))+theme(
#   strip.text.y = element_text(angle=0),
#   strip.text.x = element_text(size=8),
#   axis.text.x=element_text(angle=270)
#   )

ggplot(alldf[,],aes(year,scaled))+facet_grid(country~indicator,scales = "free",labeller = label_wrap)+
geom_rect(aes(xmin=rep(min(year),nrow(alldf)),ymin=rep(min(scaled),nrow(alldf)),xmax=rep(max(year),nrow(alldf)),ymax=rep(max(scaled),nrow(alldf)),fill=scaled))+geom_line()+theme(
  strip.text.y = element_text(angle=0),
  strip.text.x = element_text(size=8),
  axis.text.x=element_text(angle=270)
  )
alldf=alldf[1:100,]
ggplot(alldf[,],aes(x=year,y=scaled,colour=scaled))+geom_line()


+facet_grid(country~indicator,scales = "free",labeller = label_wrap)+geom_line(size=2)+theme(
  strip.text.y = element_text(angle=0),
  strip.text.x = element_text(size=8),
  axis.text.x=element_text(angle=270)
  )



```


The second graph is the beginning of an attempt to group the countries and indicators into meaningful clusters. Obviously we will need more indicators to make this useful. We extract only the latest data for each country for each indicator. 

TODO: 

- Note countries with any missing data are excluded here - that needs fixing.
- Merge Cabo Verde and Cape Verde

```{r,echo=FALSE,cache=TRUE,message=FALSE,warning=FALSE,fig.height=9}
  library(dplyr)




# summarise(group_by(df,country,value,indicator),max(year))
alldf$scaled2=as.numeric(alldf$scaled)
alldf2=select(alldf,-scaled)
alldf.g <- group_by(alldf2, country,indicator)
latest=filter(alldf.g, year == max(year))
library(reshape)
library(pheatmap)
latest$value=latest$scaled2
c=as.matrix(cast(latest,country~indicator))
c=c[,-c(3)]
# library(impute)
# c=sapply(c,impute)
pheatmap(na.omit(c),na.rm=T)

# ggplot(DF, aes(year, indicator, color=country))+geom_line(stat="identity")+xlab("Year")+ylab("")


```

There isn't much grouping of indicators - the joins are quite high up in the dendrogram on the x axis. But the countries do cluster. 

```{r}
library(RColorBrewer)
data=(data.frame(xx=rownames(c),yy=c[,1]))
# worldmap(data)
# worldmap(data,mapTitle = "",breaks=-3:3,labels=xc("a b c d e f"))

```

## Species maps using gbif

```{r}
# key <- name_backbone(name='Puma concolor')$speciesKey
# dat <- occ_search(taxonKey=key, return='data', limit=300)
# gbifmap(input=dat)
# 
# gbifmap(input=dat,region="Burkina Faso")
# (burk<- isocodes[grep("Burkina", isocodes$name), "code"])
# dat <- occ_search(country=burk, return='data', limit=300)

```

just a bit of filtering for Bin Zayeed
```{r}
library(gnumeric)
g=read.gnumeric.sheet(file = "/home/steve/steve@promente.net/Projects/IUCN/projectsAndFundsData/listOfGrants.ods", head = TRUE, sheet.name = "grants",stringsAsFactors=F) 

clist=c(CWAfNames,"Congo, Democratic Republic of (Congo-Kinshasa)","CÃ´te d'Ivoire (Ivory Coast)","Saint Helena")

gg=read.gnumeric.sheet(file = "/home/steve/steve@promente.net/Projects/IUCN/projectsAndFundsData/listOfProjects.ods", head = TRUE, sheet.name = "leftOverFromMBZ",stringsAsFactors=F) 

```





```{r MBZ}
if(!usecache){

link="http://www.speciesconservation.org/case-studies-projects/index.php?order=GrantAcceptanceDateDESC&filter_amount_all_projects=&filter_iucn_all_projects=&filter_continent_all_projects=1&LocationCountry=&filter_species_all_projects=&GrantYear=&GrantMonth=&pagesize=999999&submit=Submit"

got=getURL(link)
# pargot=htmlTreeParse(got)
pargot=htmlParse(got)
xpargot=htmlTreeParse(got)
rows=xpathSApply(pargot,"//tr")
rows=xpathSApply(pargot,"//td")
rows2=sapply(rows,function(x)as(x,"character"))

new=list()
c=0
first=F
for(i in rows2){
  if(grepl("img ",i)){
    c=c+1
    new[[c]]=clean(i)
  } else new[[c]]=c(new[[c]],clean(i))
}
content=data.frame(t(do.call(cbind,new)),stringsAsFactors = F)[,-c(1,9:15)]
colnames(content)=xc("Title Continent Country SpeciesClass USD StartDate Details")
mbz=content

mbz$Fund="MBZ"
mbz=mbz[mbz$Continent=="Africa",]
mbz$USD=gsub("\\$","",mbz$USD)
mbz$USD=gsub(",","",mbz$USD)


# mbz$NGO=""
# mbz$EndDate=""
# mbz$Report=""
library(dplyr)
mbz=select(mbz,-Continent)
write.csv(mbz,"CSVs/MBZ.csv")
saveRDS(mbz,"objects/mbz")
} else mbz=readRDS(file = "objects/mbz")



# xrows=getNodeSet(pargot,"//tr")
# xxx=xrows[[2]]


```


```{r CEPF}

if(!usecache){

link="file:///media/steve/ssd/steve@promente.net/Projects/IUCN/projectsAndFundsData/CEPF.net%20-%20Search%20the%20Project%20Database.html"

got=getURL(link)


# kbbTree <- htmlTreeParse(got, asText = TRUE)
# kbbRoot <- xmlRoot(kbbTree)
# print(summary(kbbRoot))
# kbbdiv <- kbbRoot[["body"]][["div"]]

pargot=htmlTreeParse(got, useInternalNodes = TRUE)

root=xmlRoot(pargot)
NGO=xpathSApply(pargot,"//div[@class='filterData']//div[@class='grantee']",xmlValue)
StartDate=xpathSApply(pargot,"//div[@class='filterData']//div[@class='startDate']",xmlValue)
EndDate=xpathSApply(pargot,"//div[@class='filterData']//div[@class='endDate']",xmlValue)
USD=xpathSApply(pargot,"//div[@class='filterData']//div[@class='amount']",xmlValue)
Title=xpathSApply(pargot,"//div[@class='filterData']//div[@class='title']",xmlValue)
Details=xpathSApply(pargot,"//div[@class='filterData']//div[@class='description']",xmlValue)
URL=xpathSApply(pargot,"//div[@class='filterData']//div[@class='documents']",xmlValue)

# new=list()
# for(i in 1:length((rows))){
#   for(j in 1:length(names(rows[[i]]))) if(j==1) new[[i]]=rows[[i]][[j]] else new[[i]]=c(new[[i]],rows[[i]][[j]])
# }
# 
# s=sapply(new,function(x) sapply(x,function(y)clean(as(y,"character"))))
# cepf=data.frame(t(s))[,c(2,4,6,8,10,12,14)]
# colnames(cepf)=xc("NGO StartDate EndDate USD Title Details Report")
# cepf$Continent=""
# cepf$Country=""
# cepf$SpeciesClass=""
cepf=data.frame(NGO,StartDate,EndDate,USD,Title,Details,URL)

cepf$Fund="CEPF"

write.csv(cepf,"CSVs/cepf.csv")
saveRDS(cepf,"objects/cepf")
} else cepf=readRDS(file = "objects/cepf")

```

```{r gef}
if(!usecache){

link="http://www.thegef.org/gef/project_list?keyword=&countryCode=&focalAreaCode=all&agencyCode=all&projectType=all&fundingSource=all&approvalFYFrom=all&approvalFYTo=all&ltgt=lt&ltgtAmt=&op=Search&form_build_id=form-9aCt9xrahrSa937JQ8KHkxySWx67BicZegxkUaiZDEY&form_id=prjsearch_searchfrm"
link="https://sgp.undp.org/index.php?option=com_sgpprojects&view=allprojects&limit=100&limitstart=100&paging=1"
got=getURL(link)

gef=read.csv("gef.csv",stringsAsFactors=F)
# colnames(gef)=xc("ID Country Title Focal.Area ")




#probably could use class=odd or even but I just downloaded the table as csv. but note none of the recipients seem to be small ngos. 
saveRDS(gef,"objects/gef")
} else gef=readRDS(file = "objects/gef")




```


```{r ppi}
if(!usecache){


linko="http://www.ffem.fr/accueil/PPI/recherche_Projets-PPI/ppi-afrique-centrale-orientale-australe/"
pp=xc("cameroun congo republique-centrafricaine republique-democratique-du-congo")
# pp=xc("republique-centrafricaine republique-democratique-du-congo")
content=list()
errors=list()

link=pp[[2]]
for(link in pp){
link2=paste0(linko,link,"/")
got=getURL(link2)
xpargot=htmlParse(got)
link3=xpathSApply(xpargot,"//div[@class='center_boxright']//a//@href")
for(link4 in link3){
# x=1
  got=getURL(paste0("http://www.ffem.fr",link4))
xpargot=htmlParse(got)
title=xpathSApply(xpargot,"//h1[@class='page_title']",xmlValue)
tmp=xpathSApply(xpargot,"//h2[@class='article_title']",xmlValue)
phase=tmp[[1]]

tmp2=xpathSApply(xpargot,"//div[@id='text_content']",xmlValue)
if(length(tmp2)>1) main=tmp2[[1]] else main=xpathSApply(xpargot,"//div[@class='article_item']//p",xmlValue)[[1]]
# 
# # if(length(main)<2)stop(link4)
# stop(as(main,"character"))
# browser()

implementer=str_match(main,"Porteur du projet : ([A-Z]*)")[2]
euroContribution=as.character(str_match(main,"(Contribution FFEM)(.)*([0-9]*[\\. ][0-9]*)")[1])
euroTotal=as.character(str_match(main,"([0-9]*[\\. ][0-9]* â¬)")[2])
# euroContribution=as.character(str_match(main,"([0-9]*\\.[0-9]* â¬)")[3])
# st=str_extract_all(main,"([0-9]*\\.[0-9]* â¬)")
# euroTotal=st[[1]]  
# if(length(st)>1) euroContribution=st[[2]]   else euroContribution=""
if(length(tmp2)>1) detail=tmp2[[2]] else detail=""
# browser()
URL=paste0("http://www.ffem.fr",link4)
if(length(main)>0)content[[link4]]=data.frame(Title=title,phase,More=main,Details=detail,NGO=implementer,euroContribution,euroTotal,URL) else errors[[link4]]=link4
}

}

ppi=data.frame(do.call(rbind.fill,content))
ppi$Fund="ppi"
write.csv(ppi,"CSVs/ppi.csv")
saveRDS(ppi,"objects/ppi")
} else ppi=readRDS(file = "objects/ppi")

```

```{r darwin}
if(!usecache){

link="http://www.darwininitiative.org.uk/project/location/region/sub-saharan-africa/"
got=getURL(link)
xpargot=htmlParse(got)
rows=xpathSApply(xpargot,"//table[@id='projects']//tr//td")

content=list()
link=1
for(link in seq(from=1,by=5,to=length(rows))){
proj=paste0("proj",link)
  num=clean(as(rows[[link]],"character"))
  ref=clean(as(rows[[link+1]],"character"))
  det=clean(as(rows[[link+2]],"character"))
  dat=clean(as(rows[[link+3]],"character"))
  cou=clean(as(rows[[link+4]],"character"))
pounds=regmatches(det,regexpr("\\(([^)]+)0\\)",det))
# pounds2=regmatches(pounds,regexpr("([0123456789,\\.])?",pounds))
pounds2=gsub(")","",str_sub(pounds,12,999))

detail=gsub("\\(([^)]+)0\\)","",det)
web=paste0("http://www.darwininitiative.org.uk/project/",ref,"/")
# 
isCWA=sum(sapply(CWAfNames,function(x)grepl(x,cou)))>0
if(isCWA){
got=getURL(web)
xpargot=htmlParse(got)
more=xpathSApply(xpargot,"//div[@class='ncopyw']",xmlValue)

}else more=""

content[[proj]]=c(
  num,ref,dat,cou,pounds2,detail,web,more
  )
}
darwin=t(data.frame(content))
darwin=data.frame(darwin)
darwin$Fund="Darwin"
colnames(darwin)=xc("Ref ID StartDate Country GBP Title URL Details Fund")
darwin$USD=as.numeric(gsub(",","",darwin$GBP))*1.63
write.csv(darwin,"CSVs/darwin.csv")
saveRDS(darwin,"objects/darwin")
} else darwin=readRDS(file = "objects/darwin")


```


```{r monaco}
if(!usecache){

linko="http://www.fpa2.com/projets.php?categorie="
content=list()
for (lin in 1:8){
got=getURL(paste0(linko,lin))
xpargot=htmlParse(got)
rows=xpathSApply(xpargot,"//a[@class='link_actu rs_skip']//@href")


for(path in rows){
got=getURL(paste0("http://www.fpa2.com/",path))
xpargot=htmlParse(got)
title=xpathSApply(xpargot,"//h3",xmlValue)[[1]]
ngo=xpathSApply(xpargot,"//div[@class='row']//div[@style='margin:10px;']",xmlValue)[[1]]
all=xpathSApply(xpargot,"//div[@id='article_content']",xmlValue)
StartDate=xpathSApply(xpargot,"//div[@id='article_content']//strong",xmlValue)
if(length(StartDate)==0) StartDate=""
URL=path

content[[path]]=data.frame(Title=title,NGO=ngo,Details=all,StartDate,URL)
content[[path]]$Fund="Monaco"

}
}
monaco=do.call(rbind.fill,content)
write.csv(monaco,"CSVs/monaco.csv")
saveRDS(monaco,"objects/monaco")
} else monaco=readRDS(file = "objects/monaco")


```



```{r whitley}
if(!usecache){

linko="http://whitleyaward.org/winners/"
content=list()
got=getURL(linko)
xpargot=htmlParse(got)

rows=xpathSApply(xpargot,"//tr[@class='winner-row']")
NGO=xpathSApply(xpargot,"//tr[@class='winner-row']//td[@class='po']",xmlValue)
Country=gsub("\t","",xpathSApply(xpargot,"//tr[@class='winner-row']//td[@class='pc']",xmlValue))
Type=xpathSApply(xpargot,"//tr[@class='winner-row']//td[@class='pt']",xmlValue)
StartDate=xpathSApply(xpargot,"//tr[@class='winner-row']//td[@class='py']",xmlValue)
URL=xpathSApply(xpargot,"//tr[@class='winner-row']//td[@class='po']//a//@href")


whitley=data.frame(NGO,Type,Country,StartDate,URL)
yes=sapply(whitley$Country,function(x){
  any(grepl(x,CWAfNames))
})

for(link in whitley$URL[yes]){
  got=getURL(link)
xpargot=htmlParse(got)
whitley$Title[whitley$URL==link]=xpathSApply(xpargot,"//div//*[contains(concat(' ', @class, ' '), ' standfirst ')]",xmlValue)
whitley$Details[whitley$URL==link]=xpathSApply(xpargot,"//div//*[contains(concat(' ', @class, ' '), ' hentry ')]",xmlValue)
}


whitley$Fund="whitley"
write.csv(whitley,"CSVs/whitley.csv")
saveRDS(whitley,"objects/whitley")
} else whitley=readRDS(file = "objects/whitley")


```




```{r joining}
library(plyr)
all=rbind.fill(cepf,mbz,ppi,monaco,darwin,whitley)
all$Country=as.character(all$Country)
all$USD=as.numeric(all$USD)
target=with(all,paste(Country,Details,More,Title,NGO))
all$CentralWestAfrica=sapply(target,function(x)sum(sapply(CWAfNames,function(y){
grepl(y,x)
}))>0
)


write.csv(all,"CSVs/all.csv")
```

```{r scales}
library(scales)

ggplot(all,aes(USD,group=Fund,colour=Fund))+geom_density()+scale_x_log10()
```

